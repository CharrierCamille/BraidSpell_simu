---
title: "result_analysis.Rmd"
author: "Camille Charrier"
date: "2024-10-03"
output:
  html_document:
    df_print: paged
    toc: true
    theme: lumen
    toc_float: true
    number_sections: true
    highlight: tango
    fig_caption: true
    code_folding: hide
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE,fig.align="center") 
options(encoding = 'UTF-8')
```

# - Abstract

Script of analysis for the 1st simulation, on classical effects, of the thesis

# - Pretreatments

## - Import

Load of packages needed for the further computations

```{r}
library(dplyr)
library(ggplot2)
library(stringr)
library(tidyr)
library(colorspace)
library(ggpmisc)
library(lme4)
library(lmerTest)
library(car)
library(ggpubr)
library(jsonlite)
library(tidyverse)
```


## - Plot language

```{r}
lang_plot = "french"
# lang_plot = "english"
```


## - Global variables

Load of the global variables needed for the import of databases and the plots

```{r}
path_read_known = "../results/chronolex_read_knownword_PM_X.csv"

path_read_new = "../results/chronolex_read_newword_PM_OP.csv"

path_read_pseudo = "../results/chronolex_read_pseudoword_PM_OP.csv"

path_spell_known = "../results/chronolex_spell_knownword_PM_X.csv"

path_spell_new = "../results/chronolex_spell_newword_PM_OP.csv"

path_spell_pseudo = "../results/chronolex_spell_pseudoword_PM_OP.csv"

path_stim_chronolex = "../data/external/chronolex_data.csv"

path_stim_flp = "../data/processed/flp_pseudowords_stim.csv"

path_plausible_read = "../data/processed/chronolex_reading_possiblepron.csv"

path_plausible_spell = "../data/processed/chronolex_spelling_possiblegraph.csv"

path_lexique_infra = "../data/external/Lexique_infra.csv"


cbp <- c("#FFB23D", "#38A29A", "#19609E", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

cbp2 <- c("#FFB23D", "#18578E", "#35C3B8", "#009E73",
          "#F0E442", "#0072B2", "#D55E00", "#CC79A7")

safe_colorblind_palette <- c("#88CCEE", "#CC6677", "#DDCC77",
                             "#44AA99", "#999933", "#882255", "#661100", "#6699CC", "#888888")
# scales::show_col(safe_colorblind_palette)



lab <- list(
  accuracy = if (lang_plot == "english") "Accuracy (%)" else "Taux de bonne réponse (%)",
  ortho_length = if (lang_plot == "english") "Orthographic length" else "Longueur orthographique",
  phono_length = if (lang_plot == "english") "Phonological length" else "Longueur phonologique",
  freq = if (lang_plot == "english") "Frequency" else "Fréquence",
  log_freq = if (lang_plot == "english") "Frequency (log)" else "Fréquence (log)",
  word_type = if (lang_plot == "english") "Word type" else "Type de mots",
  task = if (lang_plot == "english") "Task" else "Tâche",
  processing_time = if (lang_plot == "english") "Processing time" else "Temps de traitement",
  new_word = if (lang_plot == "english") "New words" else "Mots nouveaux",
  known_word = if (lang_plot == "english") "Known words" else "Mots connus",
  pseudo_word = if (lang_plot == "english") "Pseudowords" else "Pseudo-mots",
  read = if (lang_plot == "english") "Reading" else "Lecture",
  spell = if (lang_plot == "english") "Spelling" else "Prod. orthographique",
  regularity = if (lang_plot == "english") "Regularity" else "Régularité",
  regular = if (lang_plot == "english") "Regular" else "Régulier",
  irregular = if (lang_plot == "english") "Irregular" else "Irrégulier",
  chronolex = "Chronolex",
  high_freq = if (lang_plot =="english") "High" else "Haute fréquence",
  low_freq = if (lang_plot =="english") "Low" else "Basse fréquence",
  data_type = if (lang_plot =="english") "Data type" else "Type de données",
  simulated = if (lang_plot =="english") "Simulated" else "Simulation",
  standardized = if (lang_plot =="english") "Standardized response time" else "Temps de réponse standardisé",
  plausible = if(lang_plot== "english") "% of plausible pronunciation" else "Taux de prononciation plausible (%)",
  ortho_plausible = if(lang_plot== "english") "% of plausible orthography" else "Taux d'orthographe plausible (%)",
  ff_consistency = if(lang_plot== "english") "Feedforward consistency" else "Consistance feedforward",
  fb_consistency = if(lang_plot== "english") "Feedback consistency" else "Consistance feedback",
  high_consistency = if (lang_plot =="english") "High" else "Consistant",
  low_consistency = if (lang_plot =="english") "Low" else "Inconsistant"
)

```


## - Load data

Load the databases into dataframe variables

```{r}

raw_read_known = read.csv(path_read_known,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))
raw_read_new = read.csv(path_read_new,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))
raw_read_pseudo = read.csv(path_read_pseudo,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))
raw_spell_known = read.csv(path_spell_known,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))
raw_spell_new = read.csv(path_spell_new,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))
raw_spell_pseudo = read.csv(path_spell_pseudo,sep=",",fileEncoding="UTF-8") %>% select(-c(t,success,error_type))

# Corriger le fichier stim : on a besoin des stims complet, pas juste les items
# Vérifier également qu'on ait besoin de corriger phon dans les stims complets (déjà fait avant ou non ?)
stim_chronolex = read.csv(path_stim_chronolex,sep=",",fileEncoding="UTF-8") %>%
    mutate(Phon=gsub("8","y",Phon)) %>%
    mutate(Phon=gsub("§","&",Phon)) %>%
    mutate(Phon=gsub("1","5",Phon))

plausible_read = read.csv(path_plausible_read,sep=",",fileEncoding="UTF-8") %>% 
    mutate(possible_pronunciations=gsub("8","y",possible_pronunciations)) %>%
    mutate(possible_pronunciations=gsub("§","&",possible_pronunciations)) %>%
    mutate(possible_pronunciations=gsub("1","5",possible_pronunciations)) %>%
    mutate(possible_pronunciations = map(possible_pronunciations, ~fromJSON(gsub("'", '"', .x))))

plausible_spell = read.csv(path_plausible_spell,sep=",",fileEncoding="UTF-8")  %>%
    mutate(possible_spellings = map(possible_spellings, ~fromJSON(gsub("'", '"', .x))))

lexique_infra = read.csv(path_lexique_infra, sep=",", fileEncoding = "UTF-8") %>%
    select(-c(cgram)) %>%
    distinct()
  
stim_chronolex %>% group_by(Phon) %>% summarise(n=n())

```

## - Data processing reading

```{r}
processed_read_known = raw_read_known %>% unique() %>% mutate(num = case_when(num==0~"t_tot", num==1~"ld_ortho",num==2~"ld_phono",num==3~"phi",num==4~"let",num==5~"simu_time"))  %>% 
    pivot_wider(names_from = "num",values_from = "value")  %>% 
    mutate(t_tot = as.integer(t_tot), 
           len=nchar(word)-2, 
           task=lab$read, 
           ld_ortho=as.numeric(ld_ortho), 
           ld_phono=as.numeric(ld_phono), 
           simu_time=round(as.numeric(simu_time))) %>%
    mutate(word=gsub("!","",word),
           phi=gsub("!","", phi),
           let=gsub("!","",let)) %>%
    mutate(let=gsub("~","",let),
           phi=gsub("~","",phi)) %>%
    select(-c(test)) %>%
    mutate(condition=lab$known_word) %>%
    inner_join(stim_chronolex %>% mutate(freq=freqbooks, regularity=if_else(Nb_Irregular_GP>0,lab$irregular,lab$regular)) %>% select(c(item,len,Phon, freq,regularity)),by=c("word"="item","len"="len")) %>% 
    mutate(Phon=gsub("8","y",Phon)) %>%
    mutate(Phon=gsub("§","&",Phon)) %>%
    mutate(Phon=gsub("1","5",Phon)) %>%
    mutate(success_strict=(phi==Phon), data_type=lab$simulated) %>%
    left_join(plausible_read, by = "word")  %>%
    mutate(success_plausible = map2_lgl(
      phi, possible_pronunciations,
      ~ .x %in% .y
      ))
  

processed_read_known
  
processed_read_new = raw_read_new %>% unique() %>% mutate(num = case_when(num==0~"t_tot", num==1~"ld_ortho",num==2~"ld_phono",num==3~"phi",num==4~"let",num==5~"simu_time"))  %>% 
    pivot_wider(names_from = "num",values_from = "value")  %>% 
    mutate(t_tot = as.integer(t_tot), 
           len=nchar(word)-2, 
           task=lab$read, 
           ld_ortho=as.numeric(ld_ortho), 
           ld_phono=as.numeric(ld_phono), 
           simu_time=round(as.numeric(simu_time))) %>%
    mutate(word=gsub("!","",word),
           phi=gsub("!","", phi),
           let=gsub("!","",let)) %>%
    mutate(let=gsub("~","",let),
           phi=gsub("~","",phi)) %>%
    select(-c(test)) %>%
    mutate(condition=lab$new_word)  %>%
    inner_join(stim_chronolex  %>% select(c(item,len,Phon)),by=c("word"="item","len"="len")) %>% 
    mutate(Phon=gsub("8","y",Phon)) %>%
    mutate(Phon=gsub("§","&",Phon)) %>%
    mutate(Phon=gsub("1","5",Phon)) %>%
    mutate(success_strict=(phi==Phon), freq = 0, regularity=NA, data_type=lab$simulated) %>%
    left_join(plausible_read, by = "word")  %>%
    mutate(success_plausible = map2_lgl(
        phi, possible_pronunciations,
        ~ .x %in% .y
        ))

processed_read_new


chronolex_data = stim_chronolex %>% mutate(word=item, ld_ortho=NA, ld_phono=NA, simu_time=NA, task=lab$read, condition =lab$chronolex, phi=NA, let=NA, success_strict=NA, freq=freqbooks, t_tot=NMGrt, regularity=if_else(Nb_Irregular_GP>0,lab$irregular,lab$regular), possible_pronunciations=NA, success_plausible=NA) %>% 
    select(c(word, t_tot, ld_ortho, ld_phono, phi, let, simu_time, len, task, condition, Phon, freq, success_strict,regularity,possible_pronunciations,success_plausible)) %>% mutate(data_type=lab$chronolex)


processed_read_all = rbind(processed_read_known, processed_read_new, chronolex_data)

processed_read_all %>% filter(!success_plausible)
```

## - Data processing spelling

```{r}
processed_spell_known = raw_spell_known %>% unique() %>% mutate(num = case_when(num==0~"t_tot", num==1~"ld_ortho",num==2~"ld_phono",num==3~"phi",num==4~"let",num==5~"simu_time"))  %>% 
    pivot_wider(names_from = "num",values_from = "value")  %>% 
    mutate(t_tot = as.integer(t_tot), 
           phlen=nchar(word)-2, 
           task=lab$spell, 
           ld_ortho=as.numeric(ld_ortho), 
           ld_phono=as.numeric(ld_phono), 
           simu_time=round(as.numeric(simu_time))) %>%
    mutate(word=gsub("!","",word),
           phi=gsub("!","", phi),
           let=gsub("!","",let)) %>%
    mutate(let=gsub("~","",let),
           phi=gsub("~","",phi)) %>%
    select(-c(test)) %>%
    mutate(condition=lab$known_word) %>%
    inner_join(stim_chronolex %>% mutate (freq=freqbooks, regularity=if_else(Nb_Irregular_PG>0,lab$irregular,lab$regular)) %>% select(c(item,phlen,Phon,freq, regularity)) %>% mutate(Phon=gsub("8","y",Phon)) %>% mutate(Phon=gsub("§","&",Phon)) %>% mutate(Phon=gsub("1","5",Phon)), by=c("word"="Phon","phlen"="phlen")) %>%
    mutate(success_strict = (let==item)) %>%
    group_by(word) %>%
    summarise(t_tot=first(t_tot), ld_ortho=first(ld_ortho), ld_phono=first(ld_phono), phi=first(phi), let=first(let), simu_time=first(simu_time), phlen=first(phlen), task=first(task), condition=first(condition), item=first(item), success_strict=any(success_strict), freq=max(freq), regularity=first(regularity)) %>%
    mutate(data_type=lab$simulated) %>%
    left_join(plausible_spell, by = c("item" = "word"))  %>%
    mutate(success_plausible = map2_lgl(
      let, possible_spellings,
      ~ .x %in% .y
      )) 
    
processed_spell_known
  
processed_spell_new = raw_spell_new %>% unique() %>% mutate(num = case_when(num==0~"t_tot", num==1~"ld_ortho",num==2~"ld_phono",num==3~"phi",num==4~"let",num==5~"simu_time"))  %>% 
    pivot_wider(names_from = "num",values_from = "value")  %>% 
    mutate(t_tot = as.integer(t_tot), 
           phlen=nchar(word)-2, 
           task=lab$spell, 
           ld_ortho=as.numeric(ld_ortho), 
           ld_phono=as.numeric(ld_phono), 
           simu_time=round(as.numeric(simu_time))) %>%
    mutate(word=gsub("!","",word),
           phi=gsub("!","", phi),
           let=gsub("!","",let)) %>%
    mutate(let=gsub("~","",let),
           phi=gsub("~","",phi)) %>%
    select(-c(test)) %>%
    mutate(condition=lab$new_word) %>%
    inner_join(stim_chronolex %>% select(c(item,phlen,Phon)) %>% mutate(Phon=gsub("8","y",Phon)) %>% mutate(Phon=gsub("§","&",Phon)) %>% mutate(Phon=gsub("1","5",Phon)), by=c("word"="Phon","phlen"="phlen")) %>%
    mutate(success_strict = (let==item)) %>%
    group_by(word) %>%
    summarise(t_tot=first(t_tot), ld_ortho=first(ld_ortho), ld_phono=first(ld_phono), phi=first(phi), let=first(let), simu_time=first(simu_time), phlen=first(phlen), task=first(task), condition=first(condition), item=first(item), success_strict=any(success_strict)) %>%
    mutate(freq=0, regularity=NA, data_type=lab$simulated)  %>%
    left_join(plausible_spell, by = c("item" = "word"))  %>%
    mutate(success_plausible = map2_lgl(
      let, possible_spellings,
      ~ .x %in% .y
      ))

processed_spell_new%>% filter(!success_plausible)

processed_spell_all = rbind(processed_spell_known, processed_spell_new)


processed_spell_all 
```


# - Reading results

## - Accuracy

### - Statistical analysis

### - Lexicality effect

```{r}
processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition) %>%
    summarise(accuracy = sum(success_strict)/n()*100) 

p1 = processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition) %>%
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    ggplot(aes(x=condition,y=accuracy, fill=condition)) +
        geom_col(color="black") +
        labs(x=lab$type_word, y=lab$accuracy, fill=lab$word_type) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        ylim(0,100)+
        theme(legend.position = "none")

processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition) %>%
    summarise(plausible = sum(success_plausible)/n()*100) 

p2 = processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition) %>%
    summarise(plausible = sum(success_plausible)/n()*100) %>%
    ggplot(aes(x=condition,y=plausible, fill=condition)) +
        geom_col(color="black") +
        labs(x=lab$type_word, y=lab$plausible, fill=lab$word_type) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        ylim(0,100)+
        theme(legend.position = "none")

processed_read_all %>% filter(condition==lab$new_word & !success_plausible)

ggarrange(
  p1, p2,
  nrow = 1,
  labels = c("A","B"))

ggsave("../images/reading_lexicality_acc.png",width=6,height=4)

```


### - Length effect

```{r}
processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition, len) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n())

processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition, len) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n()) %>%
    ggplot(aes(x=len, y=(success/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$accuracy, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        ylim(0,100)

processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition, len) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n())

processed_read_all %>% filter(condition!=lab$chronolex) %>% group_by(task, condition, len) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n()) %>%
    ggplot(aes(x=len, y=(plausible/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$plausible, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        ylim(0,100)
```


### - Frequency effect

```{r}
processed_read_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    summarise(accuracy = sum(success_strict)/n()*100)

processed_read_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=class_freq,y=accuracy, fill=class_freq)) +
        geom_col(color="black") +
        labs(x=lab$freq, y=lab$accuracy, fill=lab$freq) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(80, 100))

processed_read_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    summarise(plausible = sum(success_plausible)/n()*100)

processed_read_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    summarise(plausible = sum(success_plausible)/n()*100) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=class_freq,y=plausible, fill=class_freq)) +
        geom_col(color="black") +
        labs(x=lab$freq, y=lab$plausible, fill=lab$freq) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(80, 100))
```

## - Processing time

### - Statistical analysis

```{r}

processed_read_all %>% filter(condition==lab$known_word) %>% group_by(t_tot==3000 | !success_strict) %>% summarise(n=n())
processed_read_all %>% filter(condition==lab$known_word) %>% group_by(t_tot==3000) %>% summarise(n=n())
processed_read_all %>% filter(condition==lab$known_word) %>% group_by(success_strict) %>% summarise(n=n())
processed_read_all %>% filter(condition==lab$new_word) %>% group_by(success_plausible) %>% summarise(n=n())
processed_read_all %>% filter(condition==lab$new_word) %>% group_by(t_tot==3000) %>% summarise(n=n())
processed_read_all %>% filter(condition==lab$new_word) %>% group_by(t_tot==3000 | !success_plausible) %>% summarise(n=n())

processed_read_all %>% filter(condition==lab$known_word) %>% filter(word=="dit")

# Tester la normalité pour les données humaines

shapiro.test(processed_read_all$t_tot[processed_read_all$condition == lab$chronolex])

# Pas de normalité

# Tester la normalité pour les données de simulation

shapiro.test(processed_read_all$t_tot[processed_read_all$condition == lab$known_word & processed_read_all$success_strict])

# Pas de normalité

# Test d'homogénéité des variances

leveneTest(t_tot ~ condition, data = processed_read_all %>% filter( condition == lab$chronolex | (condition == lab$known_word & success_strict)))

# Pas d'homogénéité

# Comparaison des modèles

modele_chronolex <- lm(t_tot ~ len + log(freq) ,
                           data = processed_read_all %>% filter(condition== lab$chronolex))
summary(modele_chronolex)

modele_simulated <- lm(t_tot ~ len + log(freq) ,
                           data = processed_read_all %>% filter(condition == lab$known_word & success_strict))
summary(modele_simulated)

# Modèle complet incluant lexicalité pour les données simulées

processed_read_all = processed_read_all %>% mutate(lex_binary = case_when(condition==lab$known_word~1, condition!=lab$known_word~-1))

modele_simulated <- lm(t_tot ~ len * lex_binary ,
                           data = processed_read_all %>% filter((condition == lab$known_word |condition == lab$new_word)))
                       
summary(modele_simulated)


modele_simulated <- lm(t_tot ~ len * lex_binary ,
                           data = processed_read_all %>% filter((condition == lab$known_word |condition == lab$new_word)&len>3))
                       
summary(modele_simulated)

# word type

# modele_simulated <- lm(t_tot ~  len * condition ,
#                            data = processed_read_all %>% filter(success_strict & data_type==lab$simulated) %>% mutate(condition = as.factor(condition)))
# summary(modele_simulated)


# Modèle mixte maximal (hors longueur ortho)

# modele_simulated <- lm(t_tot ~ len * log(freq) * Freq_GP * Freq_PG * regularity,
#                            data = processed_read_all %>% filter(condition == lab$known_word & success_strict) %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG)), Freq_GP = as.numeric(gsub(",", ".", Freq_GP)) ))
# summary(modele_simulated)
# 
# modele_chronolex <- lm(t_tot ~ len * log(freq) * Freq_GP * Freq_PG * regularity,
#                            data = processed_read_all %>% filter(condition== lab$chronolex) %>% 
#     mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG)), Freq_GP = as.numeric(gsub(",", ".", Freq_GP)) ))
# summary(modele_chronolex)

```


### - Lexicality effect

```{r}
processed_read_all %>% filter((condition==lab$known_word & success_strict==TRUE) | (condition==lab$new_word & success_plausible==TRUE)) %>% 
    group_by(task, condition) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) 

processed_read_all %>% filter((condition==lab$known_word & success_strict==TRUE) | (condition==lab$new_word & success_plausible==TRUE)) %>% 
    group_by(task, condition) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=condition, y=mean_time, fill=condition)) +
        geom_col(color="black") +
        geom_line(position=position_dodge(0.2)) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$word_type, y=lab$processing_time, fill=lab$word_type) +
        scale_fill_manual(values = safe_colorblind_palette)+
        theme(legend.position = "none")


ggsave("../images/reading_lexicality_pt.png",width=6,height=4)

```


### - Length x lexicality interaction 

```{r}
processed_read_all %>% filter(((condition==lab$known_word & success_strict==TRUE) | (condition==lab$new_word & success_plausible==TRUE)) & t_tot!=3000 & len>3) %>% 
    group_by(task, condition, len) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=len, y=mean_time, color=condition, shape=condition)) +
        geom_point(position=position_dodge(0.2), size=2.5) +
        geom_smooth(method = "lm", se=FALSE, formula = y ~ x)  +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$word_type, shape=lab$word_type) + 
        scale_color_manual(values = safe_colorblind_palette)

ggsave("../images/reading_length_lexicality.png",width=6,height=4)
```


### - Length effect

```{r}
processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE) ) %>% group_by(task, data_type, len) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=len, y=mean_time, color=data_type, shape=data_type)) +
        geom_point(position=position_dodge(0.2), size=2.5) +
        geom_line(position=position_dodge(0.2), size=1) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$data_type, shape=lab$data_type)+ 
        scale_color_manual(values = safe_colorblind_palette)


p1 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>% group_by(task, data_type, len) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=len, y=mean_time, color=data_type, shape=data_type))  +
        geom_smooth(method = "lm", se=FALSE, formula = y ~ x) +
        facet_wrap(. ~ data_type, scales="free_y")+
        geom_point(size=2.5) +
        theme_classic(14)+
        labs(x=lab$ortho_length,y=lab$processing_time,color=lab$data_type, shape=lab$data_type) + 
        scale_color_manual(values =safe_colorblind_palette)+
        theme(legend.position = "none")


p2 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE) ) %>%
    group_by(task, data_type) %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE)) %>%
    group_by(task, len, data_type) %>%
    summarise(n = n(),
              mean_t = mean(z_time,na.rm = TRUE),
              sd_t = sd(z_time,na.rm=TRUE)) %>%
    ggplot(aes(x=len,y=mean_t,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE,position=position_dodge(0.2))+
        geom_point(position=position_dodge(0.2), size=2.5)+
        geom_errorbar(aes(ymin=mean_t-sd_t, ymax=mean_t+sd_t), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$standardized, color=lab$data_type, shape=lab$data_type) + 
        scale_color_manual(values =safe_colorblind_palette)


ggarrange(
  p1, p2,
  nrow = 2,
  labels = c("A","B"),
  common.legend=TRUE)

ggsave("../images/reading_length.png",width=6,height=8)

```


### - Frequency effect

```{r}
processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    group_by(task,data_type) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, data_type, class_freq) %>% 
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=class_freq,y=mean_time, fill=class_freq)) +
        geom_col(color="black",position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) + 
        theme_classic(14) +
        scale_fill_manual(values =safe_colorblind_palette)+
        labs(x=lab$freq, y=lab$processing_time, fill=lab$freq) + 
        facet_wrap(. ~ data_type, scales="free_y") + 
        theme(legend.position = "none")


p1 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    ggplot(aes(x=log(freq),y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$log_freq, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) + 
        facet_wrap(. ~ data_type) + 
        theme(legend.position = "none")


p2 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    group_by(task, data_type) %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    ggplot(aes(x=log(freq),y=z_time,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        scale_color_manual(values =safe_colorblind_palette)+
        theme_classic(14) +
        labs(x=lab$log_freq, y=lab$standardized, color=lab$data_type, shape=lab$data_type)


ggarrange(
  p1, p2,
  nrow = 2,
  labels = c("A","B"),
  common.legend=TRUE)

ggsave("../images/reading_frequency.png",width=6,height=8)
```


### - Frequency x Length interaction

```{r}
processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    group_by(task,data_type) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, data_type, class_freq, len) %>% 
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=len,y=mean_time, color=class_freq, shape=class_freq)) +
        geom_smooth(method = "lm", se=FALSE, formula = y ~ x, position=position_dodge(0.2)) +
        geom_point(size=2.5, position=position_dodge(0.2)) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) + 
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$freq, shape=lab$freq) + 
        facet_wrap(. ~ data_type, scales="free_y")

processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>% 
    group_by(task, data_type) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, data_type, class_freq, len) %>% 
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=len,y=mean_time, color=class_freq, shape=class_freq)) +
        geom_smooth(method="lm", se=FALSE, position=position_dodge(0.2))+
        geom_point(size=2.5, position=position_dodge(0.2))+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$freq, shape=lab$freq) + 
        facet_wrap(. ~ data_type, scales="free_y") 

ggsave("../images/reading_frequency_length.png",width=6,height=4)

```

### - Regularity effect

```{r}
processed_read_all %>% filter(condition==lab$known_word) %>% group_by(task, condition,regularity) %>%
    summarise(accuracy = sum(success_strict)/n()*100) 

processed_read_all %>% filter(condition==lab$known_word) %>% group_by(task, condition,regularity) %>%
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    ggplot(aes(x=regularity,y=accuracy, fill=regularity)) +
        geom_col(color="black") +
        labs(x=lab$regularity, y=lab$accuracy, fill=lab$regularity) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(80, 100))+ 
        theme(legend.position = "none")

processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>% 
    group_by(task, data_type, regularity) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) 

p1 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>% 
    group_by(task, data_type, regularity) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=regularity, y=mean_time, fill=regularity)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$regularity, y=lab$processing_time, fill=lab$regularity) +
        facet_wrap(. ~ data_type, scales="free_y") +
        scale_fill_manual(values = safe_colorblind_palette)+ 
        theme(legend.position = "none")

p2 = processed_read_all %>% filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>% group_by(task, data_type) %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    group_by(task, data_type, regularity) %>%
    summarise(mean_time = mean(z_time,na.rm = TRUE), sd_time = sd(z_time,na.rm = TRUE)) %>%
    ggplot(aes(x=data_type, y=mean_time, fill=regularity)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$word_type, y=lab$standardized, fill=lab$regularity) +
        scale_fill_manual(values = safe_colorblind_palette)

ggarrange(
  p1, p2,
  nrow = 2,
  labels = c("A","B"),
  common.legend=TRUE)

ggsave("../images/reading_regularity_chronolex.png",width=6,height=8)
```


### - Feedforward consistency

```{r}
p1 = processed_read_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    ggplot(aes(x=Freq_GP,y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$ff_consistency, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) + 
        facet_wrap(. ~ data_type, scales="free_y") + 
        xlim(0,1) +
        theme(legend.position = "none")

p2 = processed_read_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    group_by(task, data_type) %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    ggplot(aes(x=Freq_GP,y=z_time,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        scale_color_manual(values =safe_colorblind_palette)+
        theme_classic(14) +
        xlim(0,1) +
        labs(x=lab$ff_consistency, y=lab$standardized, color=lab$data_type, shape=lab$data_type)

ggarrange(
  p1, p2,
  nrow = 2,
  labels = c("A","B"),
  common.legend=TRUE)

ggsave("../images/reading_fforward_chronolex.png",width=6,height=8)

processed_read_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP))) %>%
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task,data_type) %>%
    mutate(gp_median = median(Freq_GP, na.rm = TRUE), class_gp=as.factor(case_when(Freq_GP >=quantile(Freq_GP,0.75) ~ lab$high_consistency,
                                            Freq_GP <=quantile(Freq_GP,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    group_by(task, data_type, class_gp) %>%
    filter(class_gp!="Mid") %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=class_gp, y=mean_time, fill=class_gp)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$ff_consistency , y=lab$processing_time, fill=lab$ff_consistency) +
        facet_wrap(. ~ data_type, scales="free_y") +
        scale_fill_manual(values = safe_colorblind_palette)+
        theme(legend.position = "none")

processed_read_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP)))  %>%
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task, data_type) %>%
    mutate(gp_median = median(Freq_GP, na.rm = TRUE), class_gp=as.factor(case_when(Freq_GP >=quantile(Freq_GP,0.75) ~ lab$high_consistency,
                                            Freq_GP <=quantile(Freq_GP,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    filter(class_gp!="Mid") %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    group_by(task, data_type, class_gp) %>%
    summarise(mean_time = mean(z_time,na.rm = TRUE), sd_time = sd(z_time,na.rm = TRUE)) %>%
    ggplot(aes(x=data_type, y=mean_time, fill=class_gp)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$data_type, y=lab$standardized, fill=lab$ff_consistency) +
        scale_fill_manual(values = safe_colorblind_palette)

# ggarrange(
#   p1, p2,
#   nrow = 2,
#   labels = c("A","B"),
#   common.legend=TRUE)
# 
# ggsave("../images/reading_fforward_chronolex.png",width=6,height=8)

```


### - Feedback consistency

```{r}
p1 = processed_read_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    ggplot(aes(x=Freq_PG,y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$fb_consistency, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) + 
        facet_wrap(. ~ data_type, scales="free_y") + 
        xlim(0,1) +
        theme(legend.position = "none")

p2 = processed_read_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE)) %>%
    group_by(task, data_type) %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    ggplot(aes(x=Freq_PG,y=z_time,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        scale_color_manual(values =safe_colorblind_palette)+
        theme_classic(14) +
        xlim(0,1) +
        labs(x=lab$fb_consistency, y=lab$standardized, color=lab$data_type, shape=lab$data_type)

ggarrange(
  p1, p2,
  nrow = 2,
  labels = c("A","B"),
  common.legend=TRUE)

ggsave("../images/reading_fback_chronolex.png",width=6,height=8)


processed_read_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task,data_type) %>%
    mutate(pg_median = median(Freq_PG, na.rm = TRUE), class_pg=as.factor(case_when(Freq_PG >=quantile(Freq_PG,0.75) ~ lab$high_consistency, 
                                            Freq_PG <=quantile(Freq_PG,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    group_by(task, data_type, class_pg) %>%
    filter(class_pg!="Mid") %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=class_pg, y=mean_time, fill=class_pg)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$fb_consistency , y=lab$processing_time, fill=lab$fb_consistency) +
        facet_wrap(. ~ data_type, scales="free_y") +
        scale_fill_manual(values = safe_colorblind_palette)+ 
        theme(legend.position = "none") 

processed_read_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task,data_type) %>%
    mutate(pg_median = median(Freq_PG, na.rm = TRUE), class_pg=as.factor(case_when(Freq_PG >=quantile(Freq_PG,0.75) ~ lab$high_consistency, 
                                            Freq_PG <=quantile(Freq_PG,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    filter(class_pg!="Mid") %>%
    mutate(z_time = (t_tot - mean(t_tot, na.rm = TRUE)) / sd(t_tot, na.rm = TRUE))  %>%
    group_by(task, data_type, class_pg) %>%
    summarise(mean_time = mean(z_time,na.rm = TRUE), sd_time = sd(z_time,na.rm = TRUE)) %>%
    ggplot(aes(x=data_type, y=mean_time, fill=class_pg)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$data_type, y=lab$standardized, fill=lab$fb_consistency) +
        scale_fill_manual(values = safe_colorblind_palette)

processed_read_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter( (condition==lab$known_word & success_strict==TRUE))  %>%
    ggplot(aes(x=Freq_PG,y=t_tot,color=as.factor(len),shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$fb_consistency, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) + 
        facet_wrap(. ~ data_type, scales="free_y") + 
        xlim(0,1)


```

# - Spelling results

## - Accuracy

### - Lexicality effect

```{r}
processed_spell_all %>% group_by(task, condition) %>%
    summarise(accuracy = sum(success_strict)/n()*100) 

p1 = processed_spell_all %>% group_by(task, condition) %>%
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    ggplot(aes(x=condition,y=accuracy, fill=condition)) +
        geom_col(color="black") +
        labs(x=lab$type_word, y=lab$accuracy, fill=lab$word_type) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        ylim(0,100)+
        theme(legend.position = "none")

processed_spell_all %>% group_by(task, condition) %>%
    summarise(plausible = sum(success_plausible)/n()*100) 

p2 = processed_spell_all %>% group_by(task, condition) %>%
    summarise(plausible = sum(success_plausible)/n()*100) %>%
    ggplot(aes(x=condition,y=plausible, fill=condition)) +
        geom_col(color="black") +
        labs(x=lab$type_word, y=lab$ortho_plausible, fill=lab$word_type) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        ylim(0,100)+
        theme(legend.position = "none")


ggarrange(
  p1, p2,
  nrow = 1,
  labels = c("A","B"))

ggsave("../images/spelling_lexicality_acc.png",width=6,height=4)
```

### - Length effect

```{r}
processed_spell_all %>% group_by(task, condition, phlen) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n())

processed_spell_all %>% group_by(task, condition, phlen) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n()) %>%
    ggplot(aes(x=phlen, y=(success/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$phono_length, y=lab$accuracy, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        ylim(0,100)

processed_spell_all %>% mutate(len=nchar(item)) %>%
  group_by(task, condition, len) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n())

processed_spell_all %>% mutate(len = nchar(item)) %>%
    group_by(task, condition, len) %>%
    summarise(success = sum(success_strict), n=n(), p= sum(success_strict)/n()) %>%
    ggplot(aes(x=len, y=(success/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$accuracy, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        ylim(0,100)

processed_spell_all %>% group_by(task, condition, phlen) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n())

processed_spell_all %>% group_by(task, condition, phlen) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n()) %>%
    ggplot(aes(x=phlen, y=(plausible/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$phono_length, y=lab$plausible, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(0, 100))

processed_spell_all %>% mutate(len=nchar(item)) %>%
  group_by(task, condition, len) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n())

processed_spell_all %>% mutate(len = nchar(item)) %>%
    group_by(task, condition, len) %>%
    summarise(plausible = sum(success_plausible), n=n(), p= sum(success_plausible)/n()) %>%
    ggplot(aes(x=len, y=(plausible/n)*100, color=condition, shape=condition)) +
        geom_point(size=2.5) +
        geom_line(size=1) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$plausible, color=lab$word_type, shape=lab$word_type)  +
        scale_color_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(0, 100))
```


### - Frequency effect

```{r}
processed_spell_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    summarise(accuracy = sum(success_strict)/n()*100)

processed_spell_all %>% filter(condition==lab$known_word) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, condition, class_freq) %>% 
    filter(class_freq !="Mid") %>%
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    ggplot(aes(x=class_freq,y=accuracy, fill=class_freq)) +
        geom_col(color="black") +
        labs(x=lab$freq, y=lab$accuracy, fill=lab$freq) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        coord_cartesian(ylim = c(80, 100)) +
        theme(legend.position = "none")
```


## - Error analysis

## - Processing time

### - Statistical analysis

```{r}
# Tester la normalité pour les données de simulation

processed_spell_all %>% filter(condition==lab$known_word) %>% group_by(t_tot==3000 | !success_strict) %>% summarise(n=n())
processed_spell_all %>% filter(condition==lab$known_word) %>% group_by(t_tot==3000) %>% summarise(n=n())
processed_spell_all %>% filter(condition==lab$known_word) %>% group_by(success_strict) %>% summarise(n=n())

shapiro.test(processed_spell_all$t_tot[processed_spell_all$condition == lab$known_word & processed_spell_all$success_strict & processed_spell_all$t_tot!=3000])

# Pas de normalité

processed_spell_all = processed_spell_all %>% mutate(lex_binary = case_when(condition==lab$known_word~1, condition!=lab$known_word~-1), len=nchar(item))

modele_simulated <- lm(t_tot ~ phlen + len + log(freq),
                           data = processed_spell_all %>% filter((condition == lab$known_word ) & success_strict & t_tot!=3000))
summary(modele_simulated)

```


### - Lexicality effect

```{r}
processed_spell_all %>% filter((condition==lab$known_word & success_strict==TRUE) | (condition==lab$new_word & success_plausible==TRUE)) %>% 
    group_by(task, condition) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=condition, y=mean_time, fill=condition)) +
        geom_col(color="black") +
        geom_line(position=position_dodge(0.2)) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$word_type, y=lab$processing_time, fill=lab$word_type) +
        scale_fill_manual(values = safe_colorblind_palette) +
        theme(legend.position = "none")

ggsave("../images/spelling_lexicality_pt.png",width=6,height=4)
```


### - Length effect

```{r}
processed_spell_all %>% filter(condition==lab$known_word)
processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE)
processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE & t_tot!=3000)

processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE & t_tot!=3000) %>% 
    group_by(task, condition, phlen) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=phlen, y=mean_time, color=condition, shape=condition)) +
        geom_point(position=position_dodge(0.2), size=2.5) +
        geom_line(position=position_dodge(0.2),size=1) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$phono_length, y=lab$processing_time, color=lab$word_type, shape=lab$word_type) + 
        scale_color_manual(values = safe_colorblind_palette)

processed_spell_all %>% mutate(len=nchar(item)) %>%
    filter(condition==lab$known_word & success_strict==TRUE) %>% 
    group_by(task, condition, len) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=len, y=mean_time, color=condition, shape=condition)) +
        geom_point(position=position_dodge(0.2), size=2.5) +
        geom_line(position=position_dodge(0.2),size=1) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$word_type, shape=lab$word_type) + 
        scale_color_manual(values = safe_colorblind_palette)


p1 = processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE& t_tot!=3000) %>% group_by(task, condition, phlen) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=phlen, y=mean_time, color=condition, shape=condition))  +
    geom_smooth(method = "lm", se=FALSE, formula = y ~ x) +
        geom_point(size=2.5) +
        theme_classic(14)+
        labs(x=lab$phono_length,y=lab$processing_time) + 
        theme(legend.position = "none")

p2 = processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE& t_tot!=3000) %>% mutate(len=nchar(item)) %>% group_by(task, condition, len) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=len, y=mean_time, color=condition, shape=condition))  +
    geom_smooth(method = "lm", se=FALSE, formula = y ~ x) +
        geom_point(size=2.5) +
        theme_classic(14)+
        labs(x=lab$ortho_length,y=lab$processing_time) + 
        theme(legend.position = "none")

ggarrange(
  p1, p2,
  nrow = 1,
  labels = c("A","B"))

p1

ggsave("../images/spelling_length.png",width=6,height=4)

```

### - Frequency effect

```{r}
processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE & t_tot!=3000) %>%
    group_by(task,condition) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, data_type, class_freq) %>% 
    filter(class_freq !="Mid") %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=class_freq,y=mean_time, fill=class_freq)) +
        geom_col(color="black",position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge()) + 
        theme_classic(14) +
        scale_fill_manual(values =safe_colorblind_palette)+
        labs(x=lab$freq, y=lab$processing_time, fill=lab$freq) +
        theme(legend.position = "none")


processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE& t_tot !=3000) %>%
    ggplot(aes(x=log(freq),y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        theme(legend.position = "none")+
        labs(x=lab$log_freq, y=lab$processing_time, color=lab$data_type, shape=lab$data_type)

processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE & t_tot !=3000) %>%
    ggplot(aes(x=log(freq),y=t_tot,color=as.factor(phlen),shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        stat_poly_eq(formula =  y ~ x,
               use_label("eq", "R2","p"),
               parse = TRUE, coef.digits = 3, rr.digits = 3, p.digits = 3) +
        labs(x=lab$log_freq, y=lab$processing_time, color=lab$data_type, shape=lab$data_type)

```


### - Frequency x Length interaction

```{r}
processed_spell_all %>% filter(condition==lab$known_word & success_strict==TRUE & t_tot!=3000) %>% 
    group_by(task, data_type) %>%
    mutate(freq_median = median(freq, na.rm = TRUE), class_freq=as.factor(case_when(freq >=quantile(freq,0.75) ~ lab$high_freq, 
                                            freq <=quantile(freq,0.25) ~ lab$low_freq,
                                            .default = "Mid"))) %>%
    ungroup() %>%
    group_by(task, data_type, class_freq, phlen) %>% 
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    filter(class_freq!="Mid") %>%
    ggplot(aes(x=phlen,y=mean_time, color=class_freq, shape=class_freq)) +
        geom_smooth(method="lm", se=FALSE, position=position_dodge(0.2))+
        geom_point(size=2.5, position=position_dodge(0.2))+
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.2)) +
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette)+
        labs(x=lab$ortho_length, y=lab$processing_time, color=lab$freq, shape=lab$freq) 
```


### - Regularity effect

```{r}
processed_spell_all %>% filter(condition==lab$known_word) %>% group_by(task, condition,regularity) %>%
    summarise(accuracy = sum(success_strict)/n()*100) 

processed_spell_all %>% filter(condition==lab$known_word) %>% group_by(task, condition,regularity) %>%
    summarise(accuracy = sum(success_strict)/n()*100) %>%
    ggplot(aes(x=regularity,y=accuracy, fill=regularity)) +
        geom_col(color="black") +
        labs(x=lab$regularity, y=lab$accuracy, fill=lab$regularity) +
        theme_classic(14) +
        scale_fill_manual(values = safe_colorblind_palette) +
        ylim(0,100) +
        theme(legend.position = "none")

processed_spell_all %>% filter( (condition==lab$known_word & success_strict==TRUE))  %>% 
    group_by(task, data_type, regularity) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) 

processed_spell_all %>% filter((condition==lab$known_word & success_strict==TRUE))  %>% 
    group_by(task, data_type, regularity) %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=regularity, y=mean_time, fill=regularity)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$regularity, y=lab$processing_time, fill=lab$regularity) +
        scale_fill_manual(values = safe_colorblind_palette) +
        theme(legend.position = "none")
```


### - Feedforward consistency

```{r}
processed_spell_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$known_word & success_strict==TRUE)  %>%
    ggplot(aes(x=Freq_PG,y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette) +
        labs(x=lab$ff_consistency, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) +
        xlim(0,1) +
        theme(legend.position = "none") 

processed_spell_all %>% mutate(Freq_PG = as.numeric(gsub(",", ".", Freq_PG))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task,data_type) %>%
    mutate(pg_median = median(Freq_PG, na.rm = TRUE), class_pg=as.factor(case_when(Freq_PG >=quantile(Freq_PG,0.75) ~ lab$high_consistency, 
                                            Freq_PG <=quantile(Freq_PG,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    group_by(task, data_type, class_pg) %>%
    filter(class_pg!="Mid") %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=class_pg, y=mean_time, fill=class_pg)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$ff_consistency , y=lab$processing_time, fill=lab$ff_consistency) +
        scale_fill_manual(values = safe_colorblind_palette)+ 
        theme(legend.position = "none") 
```



### - Feedback consistency

```{r}
processed_spell_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP))) %>% 
    filter(condition==lab$known_word & success_strict==TRUE)  %>%
    ggplot(aes(x=Freq_GP,y=t_tot,color=data_type,shape=data_type))+
        geom_smooth(method="lm",se=FALSE)+
        geom_point()+
        theme_classic(14) +
        scale_color_manual(values =safe_colorblind_palette) +
        labs(x=lab$fb_consistency, y=lab$processing_time, color=lab$data_type, shape=lab$data_type) +
        xlim(0,1) +
        theme(legend.position = "none") 

processed_spell_all %>% mutate(Freq_GP = as.numeric(gsub(",", ".", Freq_GP))) %>% 
    filter(condition==lab$chronolex | (condition==lab$known_word & success_strict==TRUE))  %>%
    group_by(task,data_type) %>%
    mutate(gp_median = median(Freq_GP, na.rm = TRUE), class_gp=as.factor(case_when(Freq_GP >=quantile(Freq_GP,0.75) ~ lab$high_consistency, 
                                            Freq_GP <=quantile(Freq_GP,0.25) ~ lab$low_consistency,
                                            .default = "Mid"))) %>%
    group_by(task, data_type, class_gp) %>%
    filter(class_gp!="Mid") %>%
    summarise(mean_time = mean(t_tot,na.rm = TRUE), sd_time = sd(t_tot,na.rm = TRUE)) %>%
    ggplot(aes(x=class_gp, y=mean_time, fill=class_gp)) +
        geom_col(color="black", position=position_dodge()) +
        geom_errorbar(aes(ymin=mean_time-sd_time, ymax=mean_time+sd_time), width=.2,
                 position=position_dodge(0.8)) +
        theme_classic(14) +
        labs(x=lab$fb_consistency , y=lab$processing_time, fill=lab$fb_consistency) +
        scale_fill_manual(values = safe_colorblind_palette)+ 
        theme(legend.position = "none") 
```



