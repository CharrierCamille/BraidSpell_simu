{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simulations with the model BRAID-Acq\n",
    "\n",
    "## 1. Behavioral effects\n",
    "### A. Simulation of the word length effect for known words and novel words\n",
    "\n",
    "The length effect refers to the fact that longer words may take more time to process than shorter words.\n",
    "Studies in children suggest that this effect tends to decrease early in the reading learning process.\n",
    "In Italian children with 1, 2, or 3 years of reading experience, a clear change in the length effect is observed between the first and second year of learning (Zoccolotti et al., 2005).\n",
    "A similar rapid change is found in English after the second year of learning in a categorization task (Samuels et al., 1978).\n",
    "A pronounced length effect indicates the use of a purely serial procedure as opposed to a parallel one (Zoccolotti et al., 2005).\n",
    "In the context of dual-route models, this opposition between serial and parallel is often interpreted as a distinction between sublexical and lexical processing.\n",
    "However, it has been shown that a high length effect on known words can be generated by increasing inter-letter spacing (Risko et al., 2011).\n",
    "Similarly, an effect of word length is observed in children, despite evidence against the use of a sublexical procedure (van den Boer et al., 2012).\n",
    "The origin of the length effect may be related to visual processing of the stimulus (van den Boer et al., 2012).\n",
    "The structure of the BRAID model allows us to explore this idea, especially through implemented visual attention processes.\n",
    "\n",
    "### B. Simulation of the lexicality effect\n",
    "The lexicality effect refers to the difference in processing between real words and non-words.\n",
    "In terms of reading times, it has been showed that real words are recognized more quickly and accurately than non-words,\n",
    "even from the beginning stages of reading acquisition (sprenger-charolles, 2005).\n",
    "This underscores the importance of lexical knowledge in the reading process.\n",
    "In dual-route models, the lexicality effect arises from the differing procedures employed for reading novel and familiar words.\n",
    "When decoding novel words, grapheme-phoneme conversions are used, a relatively slower process, whereas the recognition of known words relies on a faster direct recognition mechanism.\n",
    "In the BRAID-Acq model, a single procedure is implemented for both known and novel words.\n",
    "However, the model incorporates top-down lexical feedback, which accelerates letter recognition during the reading of known words, leading to reduced reading times.\n",
    "\n",
    "\n",
    "## 2. Informatic implementation for the reproduction of the 2 effects\n",
    "\n",
    "The 2 effects will be assessed using the same simulation. Code will be divided in several parts, see further explanations below:\n",
    "\n",
    "* A - Imports, to be adapted at each simulation with specific libraries, but the first part (before specific libraries) is the same for every simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#######################\n",
    "### A - Imports ######\n",
    "######################\n",
    "\n",
    "braidPath = \"../\"\n",
    "import sys\n",
    "sys.path.append(braidPath)\n",
    "\n",
    "from braidpy.simu import simu\n",
    "from braidpy.expe import expe\n",
    "\n",
    "# specific libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* B - Model init, see the notebook one_word.ipynb in the same directory for more explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 8\n",
      "max length = 7\n",
      "mod : phono coupling_a : 0.7573621975590991, coupling_b : 0.4505811026362787\n",
      "mod : ortho coupling_a : 0.7402617815647823, coupling_b : 2.221674635970171\n",
      "max length = 8\n",
      "max length = 7\n",
      "mod : phono coupling_a : 0.7573621975590991, coupling_b : 0.4505811026362787\n",
      "mod : ortho coupling_a : 0.7402617815647823, coupling_b : 2.221674635970171\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "### B - Model init ####\n",
    "######################\n",
    "\n",
    "def simu_definition(novel=True):\n",
    "    simu_param={\"level\":\"expe\",\"max_iter\":2000, \"t_min\":50, \"simu_type\":\"H\", \"thr_expo\":0.1, \"stop_criterion_type\":\"pMean\", \"serial_reading\":False}\n",
    "    simu_args={}\n",
    "    model_param={\"langue\":\"fr\", \"path\":braidPath}\n",
    "    ortho_param = {\"stim\":\"partir\",\"learning\":False, \"remove_stim\":novel,\"sd\":1, 'Q':1}\n",
    "    phono_param = {\"learning\":False, \"remove_stim\":False}\n",
    "    semantic_param = {\"context_sem\":False}\n",
    "    sim = simu(model_param, ortho_param, phono_param, semantic_param, simu_args, **simu_param)\n",
    "    return sim\n",
    "\n",
    "# simulation for orthographically novel words\n",
    "sim_novel=simu_definition(True)\n",
    "\n",
    "# simulation for orthographically known words\n",
    "sim_known=simu_definition(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* C - Experiment init\n",
    "    * liste : should be a list of words. If not provided, words are selected randomly.\n",
    "    * lenMin, lexMax, n_stim_len : if random selection (i.e. liste not provided), selects n_stim_len random words per word length, between lenMin and lenMax, both included.\n",
    "    * res_fct_name : the name of the result function, see simu documentation for more details about authorized names. Here are some examples:\n",
    "        * t_tot : total reading time\n",
    "        * phi : the decoded pronunciation\n",
    "        * wphi : the phonological identified word\n",
    "        * wl : the orthographic identified word\n",
    "        * wfusion : the word identified overall\n",
    "    * basename : the name of the file to save results.\n",
    "        * Results will be saved in csv and pkl format.\n",
    "        * basename will be completed with an extension accoding to the model's knowledge of the word:\n",
    "            * PM_X : known in both modalities\n",
    "            * PM_O : novel in the ortho modality\n",
    "            * PM_P : novel in the phono modality\n",
    "            * PM_OP : novel in both modalities\n",
    "    * n_expo : int. number of exposures for each stimulus.\n",
    "    * test : dictionary, with keys the names of the parameters, and values the values to be tested for each parameter. Specific parameters you want to test the influence on results. The cross product of all parameters will be tested.\n",
    "        * ex : test={\"context_sem\":[False,True],\"max_iter\":[500,1000,1500]} -> the 6 combination values will be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "### C - Expe init ####\n",
    "######################\n",
    "\n",
    "expe_param = {\"res_fct_name\":[\"t_tot\"],\n",
    "              \"basename\":\"first_simulation\",\n",
    "              \"n_expo\":1,\n",
    "              \"test\":{\"context_sem\":[False]},\n",
    "              \"liste\":None,\n",
    "              \"lenMin\":4,\"lenMax\":8,\"n_stim_len\":5}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* D - Experiment simulation\n",
    "    * you must pass the dictionary of experiment parameters to the class constructor.\n",
    "    * the function to call is \"compare_param\" because usually several parameters and their influence on results are compared, through the dictionary called \"test\".\n",
    "        * if there is no comparison of parameters, put one parameter with one value, like test={\"context_sem\":True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXPE:root:['rush', 'khan', 'casa', 'loco', 'item', 'serin', 'ultra', 'clash', 'créer', 'hiver', 'assagi', 'veille', 'spasme', 'toison', 'souler', 'briseur', 'dessert', 'haleine', 'caniche', 'repérer'] \n",
      " csv/first_simulation_PM_O.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin expe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "EXPE:root:rush 0/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mil begin expe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "EXPE:root:khan 1/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rush {'context_sem': False} [2000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 6 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "EXPE:root:casa 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "khan {'context_sem': False} [2000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "WARNING:root:bad ortho position is trying to be set : 5 4\n",
      "WARNING:root:bad ortho position is trying to be set : 4 4\n",
      "EXPE:root:loco 3/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "casa {'context_sem': False} [2000]\n"
     ]
    }
   ],
   "source": [
    "#######################\n",
    "### D - Simulations ##\n",
    "#####################print(df.head(50))#\n",
    "\n",
    "### Conducting the simulation on novel words\n",
    "exp = expe(simu=sim_novel,**expe_param)\n",
    "exp.compare_param()\n",
    "\n",
    "### Conducting the simulation on known words\n",
    "exp = expe(simu=sim_known,**expe_param)\n",
    "exp.compare_param()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* E - Results\n",
    "    * The results are csv files, with columns:\n",
    "        * word : name if the stimulus\n",
    "        * t : time (exposure or iteration, according to the simulation)\n",
    "        * num : for results of length >1, the num-th item of the result\n",
    "        * some other params : the params that are keys of dictionary \"test\" in the expe configuration\n",
    "        * success : if it has a meaning, success of the result\n",
    "        * error_type : if it has a meaning, type of error made by the model\n",
    "    * To exploit the results, the csv has to be extracted for the 2 simulations (novel and known word).\n",
    "    Then a unique dataframe is constructed using those 2 dataframes, and results are plotted using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#######################\n",
    "### E - Results ######\n",
    "######################\n",
    "\n",
    "df_known=pd.read_csv('csv/first_simulations_PM_X.csv')\n",
    "df_novel=pd.read_csv('csv/first_simulations_PM_O.csv')\n",
    "\n",
    "# creating a unique dataframe with length and novelty info\n",
    "df_known['length']=df_known.word.str.len()\n",
    "df_known['novelty']='known'\n",
    "df_novel['length']=df_novel.word.str.len()\n",
    "df_novel['novelty']='novel'\n",
    "df=pd.concat([df_known,df_novel])[['value','length','novelty','word']]\n",
    "\n",
    "\n",
    "# plot\n",
    "\n",
    "pivot_df = df[['length','novelty','value']].groupby(['length','novelty']).mean().reset_index().pivot(index='length', columns='novelty', values='value')\n",
    "pivot_df.plot(ylabel=\"reading time\")\n",
    "plt.xticks(range(4,9))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braid_env_poetry",
   "language": "python",
   "name": "braid_env_poetry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
